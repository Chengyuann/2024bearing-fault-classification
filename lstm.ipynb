{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# 加载数据的函数\n",
    "def load_data(directory, sequence_length=4096):\n",
    "    X, y = [], []\n",
    "    for label in range(4):  # 四种状态\n",
    "        folder = os.path.join(directory, str(label))\n",
    "        for file in os.listdir(folder):\n",
    "            if file.endswith('.txt'):\n",
    "                file_path = os.path.join(folder, file)\n",
    "                with open(file_path, 'r') as f:\n",
    "                    waveform = [float(line.strip()) for line in f.readlines()]\n",
    "                    if len(waveform) == sequence_length:\n",
    "                        X.append(waveform)\n",
    "                        y.append(label)\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    return X, y\n",
    "\n",
    "# 加载测试数据的函数\n",
    "def load_test_data(test_directory, sequence_length=4096):\n",
    "    X_test = []\n",
    "    for i in range(2000):  # 根据您的文件数量调整\n",
    "        file_path = os.path.join(test_directory, f\"{i}.txt\")\n",
    "        df = pd.read_csv(file_path, sep='\\t', header=None).T\n",
    "        waveform = df.values.flatten()\n",
    "        if len(waveform) == sequence_length:\n",
    "            X_test.append(waveform)\n",
    "    X_test = np.array(X_test)\n",
    "    return X_test\n",
    "\n",
    "# 重塑数据以适应LSTM输入\n",
    "def reshape_data(X):\n",
    "    return X.reshape((X.shape[0], X.shape[1], 1))\n",
    "\n",
    "# 加载训练数据\n",
    "X, y = load_data('data/train')\n",
    "X = reshape_data(X)\n",
    "y = to_categorical(y, num_classes=4)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 加载测试数据\n",
    "X_test = load_test_data('data/test1')\n",
    "X_test = reshape_data(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练数据维度:  (3200, 4096, 1)\n",
      "验证数据维度:  (800, 4096, 1)\n",
      "测试数据维度:  (2000, 4096, 1)\n",
      "训练标签维度:  (3200, 4)\n",
      "验证标签维度:  (800, 4)\n",
      "训练样本示例:\n",
      " [[[-0.58664616]\n",
      "  [-0.94184249]\n",
      "  [-0.25689108]\n",
      "  ...\n",
      "  [-0.39397053]\n",
      "  [ 0.40303024]\n",
      "  [-2.12762123]]\n",
      "\n",
      " [[-0.24358047]\n",
      "  [-0.37693999]\n",
      "  [ 1.24655105]\n",
      "  ...\n",
      "  [ 3.09291723]\n",
      "  [ 2.64895901]\n",
      "  [ 1.81705709]]]\n",
      "测试样本示例:\n",
      " [[[ -2.29395955]\n",
      "  [ -0.51380474]\n",
      "  [  1.34389521]\n",
      "  ...\n",
      "  [ -0.77486932]\n",
      "  [  0.55476074]\n",
      "  [ -0.66728662]]\n",
      "\n",
      " [[ -9.38502737]\n",
      "  [ 25.77933458]\n",
      "  [ 31.80100779]\n",
      "  ...\n",
      "  [-69.92468496]\n",
      "  [-32.02012487]\n",
      "  [ 18.34911875]]]\n",
      "训练集标签分布:  {0: 791, 1: 787, 2: 806, 3: 816}\n",
      "验证集标签分布:  {0: 209, 1: 213, 2: 194, 3: 184}\n"
     ]
    }
   ],
   "source": [
    "# 查看数据维度\n",
    "print(\"训练数据维度: \", X_train.shape)\n",
    "print(\"验证数据维度: \", X_val.shape)\n",
    "print(\"测试数据维度: \", X_test.shape)\n",
    "\n",
    "# 查看标签的维度\n",
    "print(\"训练标签维度: \", y_train.shape)\n",
    "print(\"验证标签维度: \", y_val.shape)\n",
    "\n",
    "# 查看一些训练样本\n",
    "print(\"训练样本示例:\\n\", X_train[:2])\n",
    "\n",
    "# 查看一些测试样本\n",
    "print(\"测试样本示例:\\n\", X_test[:2])\n",
    "\n",
    "# 检查训练标签分布\n",
    "unique, counts = np.unique(np.argmax(y_train, axis=1), return_counts=True)\n",
    "print(\"训练集标签分布: \", dict(zip(unique, counts)))\n",
    "\n",
    "# 检查验证标签分布\n",
    "unique, counts = np.unique(np.argmax(y_val, axis=1), return_counts=True)\n",
    "print(\"验证集标签分布: \", dict(zip(unique, counts)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch data size: torch.Size([64, 64, 64])\n",
      "Batch target size: torch.Size([64, 4])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# 定义重塑数据的函数\n",
    "def reshape_data_for_lstm(X):\n",
    "    # 重塑数据为 (batch_size, 64, 64)\n",
    "    batch_size = X.shape[0]\n",
    "    return X.reshape(batch_size, 64, 64)\n",
    "\n",
    "# 将数据从 numpy 数组转换为 PyTorch 张量，并应用重塑\n",
    "X_train_tensor = torch.tensor(reshape_data_for_lstm(X_train.squeeze(-1)), dtype=torch.float32)\n",
    "X_val_tensor = torch.tensor(reshape_data_for_lstm(X_val.squeeze(-1)), dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(reshape_data_for_lstm(X_test.squeeze(-1)), dtype=torch.float32)\n",
    "\n",
    "# 转换标签为 PyTorch 张量\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long).squeeze()\n",
    "y_val_tensor = torch.tensor(y_val, dtype=torch.long).squeeze()\n",
    "\n",
    "# 创建 TensorDataset\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "\n",
    "# 创建 DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# 验证 DataLoader 输出\n",
    "for data, target in train_loader:\n",
    "    print(\"Batch data size:\", data.size())  # 应该输出: torch.Size([64, 64, 64])\n",
    "    print(\"Batch target size:\", target.size())\n",
    "    break  # 只打印第一批次的信息\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch data size: torch.Size([64, 64, 64])\n",
      "Batch target size: torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "# one-hot 编码标签转换为整数索引\n",
    "y_train_indices = np.argmax(y_train, axis=1)\n",
    "y_val_indices = np.argmax(y_val, axis=1)\n",
    "\n",
    "# 转换为 PyTorch 张量\n",
    "y_train_tensor = torch.tensor(y_train_indices, dtype=torch.long)\n",
    "y_val_tensor = torch.tensor(y_val_indices, dtype=torch.long)\n",
    "\n",
    "# 重新创建 TensorDataset\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "\n",
    "# 重新创建 DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# 再次验证 DataLoader 输出\n",
    "for data, target in train_loader:\n",
    "    print(\"Batch data size:\", data.size())  # 应该输出: torch.Size([64, 64, 64])\n",
    "    print(\"Batch target size:\", target.size())  # 应该输出: torch.Size([64])\n",
    "    break  # 只打印第一批次的信息\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTMClassifier(\n",
      "  (lstm_layers): ModuleList(\n",
      "    (0): LSTM(64, 256, batch_first=True)\n",
      "    (1): LSTM(256, 128, batch_first=True)\n",
      "    (2): LSTM(128, 64, batch_first=True)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=64, out_features=4, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        # LSTM 层\n",
    "        self.lstm_layers = nn.ModuleList([\n",
    "            nn.LSTM(64, 256, batch_first=True),\n",
    "            nn.LSTM(256, 128, batch_first=True),\n",
    "            nn.LSTM(128, 64, batch_first=True)\n",
    "        ])\n",
    "        \n",
    "        # 分类器\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(64, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(64, 4)  # 输出层，因为您有 4 个类别\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # 通过 LSTM 层\n",
    "        for lstm_layer in self.lstm_layers:\n",
    "            x, _ = lstm_layer(x)\n",
    "        \n",
    "        # 取 LSTM 最后一层的最后一个时间步的输出\n",
    "        x = x[:, -1, :]\n",
    "        \n",
    "        # 通过分类器\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "# 创建模型实例\n",
    "model = LSTMClassifier()\n",
    "\n",
    "# 打印模型结构\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将模型移动到正确的设备\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 Train loss: 1.1246 Acc: 0.4384\n",
      "Validation loss: 0.9249 Acc: 0.4713\n",
      "Epoch 2/50 Train loss: 0.9432 Acc: 0.4966\n",
      "Validation loss: 0.9176 Acc: 0.4888\n",
      "Epoch 3/50 Train loss: 0.9271 Acc: 0.5034\n",
      "Validation loss: 0.9114 Acc: 0.4888\n",
      "Epoch 4/50 Train loss: 0.9190 Acc: 0.4947\n",
      "Validation loss: 0.9163 Acc: 0.4713\n",
      "Epoch 5/50 Train loss: 0.9187 Acc: 0.5219\n",
      "Validation loss: 0.9310 Acc: 0.6200\n",
      "Epoch 6/50 Train loss: 0.9919 Acc: 0.5941\n",
      "Validation loss: 0.9442 Acc: 0.5400\n",
      "Epoch 7/50 Train loss: 0.8780 Acc: 0.5797\n",
      "Validation loss: 0.7250 Acc: 0.7000\n",
      "Epoch 8/50 Train loss: 0.8765 Acc: 0.6034\n",
      "Validation loss: 1.0087 Acc: 0.5400\n",
      "Epoch 9/50 Train loss: 0.9738 Acc: 0.5572\n",
      "Validation loss: 0.9647 Acc: 0.5575\n",
      "Epoch 10/50 Train loss: 0.8411 Acc: 0.6231\n",
      "Validation loss: 0.8285 Acc: 0.6075\n",
      "Epoch 11/50 Train loss: 0.8570 Acc: 0.6081\n",
      "Validation loss: 0.8929 Acc: 0.6012\n",
      "Epoch 12/50 Train loss: 0.6251 Acc: 0.6900\n",
      "Validation loss: 0.5257 Acc: 0.7350\n",
      "Epoch 13/50 Train loss: 0.4393 Acc: 0.7500\n",
      "Validation loss: 0.4760 Acc: 0.7638\n",
      "Epoch 14/50 Train loss: 0.4139 Acc: 0.7619\n",
      "Validation loss: 0.4630 Acc: 0.7837\n",
      "Epoch 15/50 Train loss: 0.3993 Acc: 0.7775\n",
      "Validation loss: 0.4378 Acc: 0.7963\n",
      "Epoch 16/50 Train loss: 0.3960 Acc: 0.7869\n",
      "Validation loss: 0.4250 Acc: 0.8025\n",
      "Epoch 17/50 Train loss: 0.3857 Acc: 0.8056\n",
      "Validation loss: 0.4024 Acc: 0.8187\n",
      "Epoch 18/50 Train loss: 0.3568 Acc: 0.8253\n",
      "Validation loss: 0.3703 Acc: 0.8375\n",
      "Epoch 19/50 Train loss: 0.2986 Acc: 0.8741\n",
      "Validation loss: 0.3201 Acc: 0.8762\n",
      "Epoch 20/50 Train loss: 0.2587 Acc: 0.8981\n",
      "Validation loss: 0.2878 Acc: 0.9075\n",
      "Epoch 21/50 Train loss: 0.2012 Acc: 0.9347\n",
      "Validation loss: 0.2499 Acc: 0.9113\n",
      "Epoch 22/50 Train loss: 0.1688 Acc: 0.9528\n",
      "Validation loss: 0.2831 Acc: 0.9187\n",
      "Epoch 23/50 Train loss: 0.1654 Acc: 0.9550\n",
      "Validation loss: 0.2011 Acc: 0.9375\n",
      "Epoch 24/50 Train loss: 0.1489 Acc: 0.9584\n",
      "Validation loss: 0.2928 Acc: 0.9087\n",
      "Epoch 25/50 Train loss: 0.1531 Acc: 0.9597\n",
      "Validation loss: 0.2146 Acc: 0.9313\n",
      "Epoch 26/50 Train loss: 0.1416 Acc: 0.9581\n",
      "Validation loss: 0.2090 Acc: 0.9375\n",
      "Epoch 27/50 Train loss: 0.1164 Acc: 0.9706\n",
      "Validation loss: 0.2017 Acc: 0.9400\n",
      "Epoch 28/50 Train loss: 0.1166 Acc: 0.9650\n",
      "Validation loss: 0.2111 Acc: 0.9450\n",
      "Epoch 29/50 Train loss: 0.1090 Acc: 0.9697\n",
      "Validation loss: 0.2335 Acc: 0.9375\n",
      "Epoch 30/50 Train loss: 0.0979 Acc: 0.9747\n",
      "Validation loss: 0.2090 Acc: 0.9425\n",
      "Epoch 31/50 Train loss: 0.0953 Acc: 0.9728\n",
      "Validation loss: 0.2149 Acc: 0.9425\n",
      "Epoch 32/50 Train loss: 0.1407 Acc: 0.9563\n",
      "Validation loss: 0.2807 Acc: 0.9100\n",
      "Epoch 33/50 Train loss: 0.1325 Acc: 0.9569\n",
      "Validation loss: 0.2049 Acc: 0.9413\n",
      "Epoch 34/50 Train loss: 0.0917 Acc: 0.9725\n",
      "Validation loss: 0.2165 Acc: 0.9437\n",
      "Early stopping triggered after 34 epochs!\n"
     ]
    }
   ],
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=100, patience=6):\n",
    "    best_acc = 0.0\n",
    "    best_model_wts = None\n",
    "    epochs_no_improve = 0  # 跟踪没有改进的 epochs 数\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "\n",
    "        # 训练阶段\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        epoch_acc = running_corrects.double() / len(train_loader.dataset)\n",
    "        print(f'Epoch {epoch+1}/{num_epochs} Train loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "        # 验证阶段\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_corrects = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                val_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        val_loss = val_loss / len(val_loader.dataset)\n",
    "        val_acc = val_corrects.double() / len(val_loader.dataset)\n",
    "        print(f'Validation loss: {val_loss:.4f} Acc: {val_acc:.4f}')\n",
    "\n",
    "        # 早停逻辑\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            best_model_wts = model.state_dict()\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(f'Early stopping triggered after {epoch+1} epochs!')\n",
    "            break\n",
    "\n",
    "    # 加载最佳模型权重\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model\n",
    "\n",
    "# 训练模型，包含早停\n",
    "best_model = train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=50, patience=6)\n",
    "\n",
    "# 保存最佳模型权重\n",
    "torch.save(best_model.state_dict(), 'best_lstm_model.pth')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 确保模型处于评估模式\n",
    "best_model.eval()\n",
    "\n",
    "# 创建测试集的 DataLoader\n",
    "test_loader = DataLoader(TensorDataset(X_test_tensor), batch_size=64, shuffle=False)\n",
    "\n",
    "# 进行预测\n",
    "pred_y = []\n",
    "with torch.no_grad():\n",
    "    for inputs in test_loader:\n",
    "        inputs = inputs[0].to(device)\n",
    "        outputs = best_model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        pred_y.extend(preds.cpu().numpy())\n",
    "\n",
    "# 将预测结果转换为 NumPy 数组\n",
    "pred_y = np.array(pred_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 创建 DataFrame 并保存预测结果\n",
    "df_test = pd.DataFrame()\n",
    "df_test[\"label\"] = pred_y\n",
    "df_test.to_csv('predicted_labels.csv', index=False, header=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy: 0.9828\n",
      "Validation set accuracy: 0.9437\n"
     ]
    }
   ],
   "source": [
    "# 准确率计算函数\n",
    "def calculate_accuracy(model, data_loader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in data_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    return correct / total\n",
    "\n",
    "# 计算训练集上的准确率\n",
    "train_accuracy = calculate_accuracy(best_model, train_loader)\n",
    "print(f'Training set accuracy: {train_accuracy:.4f}')\n",
    "\n",
    "# 计算验证集上的准确率\n",
    "val_accuracy = calculate_accuracy(best_model, val_loader)\n",
    "print(f'Validation set accuracy: {val_accuracy:.4f}')\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

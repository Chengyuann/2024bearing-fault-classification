{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\15356\\AppData\\Roaming\\Python\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "import scipy.stats\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from tqdm.auto import tqdm\n",
    "from scipy.fftpack import fft\n",
    "from scipy.stats import skew, kurtosis\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold,KFold,train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_train_multiclassifier(df_train, df_test, feats, seed, label_name, n_fold=10):\n",
    "    skf = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=seed)\n",
    "    train_label = df_train[label_name]\n",
    "    label_num = int(train_label.max() + 1)\n",
    "    i = 0\n",
    "    importance = 0\n",
    "    pred_y = 0\n",
    "    oof = np.zeros([len(df_train), label_num])\n",
    "    pred_y = np.zeros([len(df_test), label_num])\n",
    "    params = {\n",
    "        'learning_rate': 0.15,\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'multiclass',\n",
    "        'num_class': label_num,\n",
    "        'metric': 'multi_error',\n",
    "        'num_leaves': 10,\n",
    "        'verbose': -1,\n",
    "        'seed': 42,\n",
    "        'n_jobs': -1,\n",
    "        'feature_fraction': 0.1,\n",
    "        'bagging_fraction': 0.1,\n",
    "    }\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(df_train, train_label)):\n",
    "        print('---------------------------', fold)\n",
    "        train = lgb.Dataset(df_train.loc[train_idx, feats],\n",
    "                            df_train.loc[train_idx, label_name])\n",
    "        val = lgb.Dataset(df_train.loc[val_idx, feats],df_train.loc[val_idx, label_name])\n",
    "        model = lgb.train(params, train, valid_sets=val, num_boost_round=20000,\n",
    "                          callbacks=[lgb.early_stopping(100), lgb.log_evaluation(500)])\n",
    "        oof[val_idx] = model.predict(df_train.loc[val_idx, feats])\n",
    "        importance += model.feature_importance(importance_type='gain') / n_fold\n",
    "        pred_y += model.predict(df_test[feats].to_numpy()) / n_fold\n",
    "    feats_importance = pd.DataFrame()\n",
    "    feats_importance['name'] = feats\n",
    "    feats_importance['importance'] = importance\n",
    "    return pred_y, oof, feats_importance.sort_values(\"importance\", ascending=False)\n",
    "                  \n",
    "def extract_segmented_features(data, segment_size=256, start_point=128):\n",
    "    num_segments = (data.shape[1] - start_point) // segment_size\n",
    "                     \n",
    "    segmented_features_list = []\n",
    "    for i in range(num_segments):\n",
    "        start_idx = start_point + i * segment_size\n",
    "        end_idx = start_idx + segment_size\n",
    "        \n",
    "        segment_data = data[:, start_idx:end_idx]\n",
    "\n",
    "        mean = np.mean(segment_data, axis=1)\n",
    "        std = np.std(segment_data, axis=1)\n",
    "        median = np.median(segment_data, axis=1)\n",
    "        skewness = skew(segment_data, axis=1)\n",
    "        kurt = kurtosis(segment_data, axis=1)\n",
    "        \n",
    "        # 频域特征\n",
    "        fft_result = fft(segment_data, axis=1)\n",
    "        fft_magnitude = np.abs(fft_result)\n",
    "        max_freq_index = np.argmax(fft_magnitude, axis=1)\n",
    "        max_freq = np.fft.fftfreq(segment_data.shape[1])[max_freq_index]\n",
    "        echo_intervals = np.argmax(fft_result[:, 1:], axis=1) + 1  \n",
    "        features_dict = {\n",
    "            'mean': mean,\n",
    "            'std': std,\n",
    "            'median': median,\n",
    "            'skewness': skewness,\n",
    "            'kurtosis': kurt,\n",
    "            'max_freq': max_freq,\n",
    "        }\n",
    "\n",
    "        features_df = pd.DataFrame(features_dict)\n",
    "        segmented_features_list.append(features_df)\n",
    "    combined_features_df = pd.concat(segmented_features_list, axis=1)\n",
    "    feature_names = [f\"{start_point}_{segment_size}_{stat}_{i+1}\" for stat in features_dict.keys() for i in range(num_segments)]\n",
    "    combined_features_df.columns = feature_names\n",
    "    return combined_features_df,feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path=\"data/test1/\"\n",
    "dfs = []\n",
    "for i in range(0,2000):\n",
    "    file_path=test_path+str(i)+\".txt\"\n",
    "    df = pd.read_csv(file_path, sep='\\t', header=None)\n",
    "    df=df.T\n",
    "    dfs.append(df)\n",
    "\n",
    "df_test = pd.concat(dfs).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = []\n",
    "for i in range(4):\n",
    "    train_path=\"data/train/%d\"%i\n",
    "    dfs = []\n",
    "    for file_name in os.listdir(train_path):\n",
    "        if file_name.endswith('.txt'):\n",
    "            file_path = os.path.join(train_path, file_name)\n",
    "            df = pd.read_csv(file_path, sep='\\t', header=None)\n",
    "            dfs.append(df.T)\n",
    "\n",
    "    df_train = pd.concat(dfs)         \n",
    "    df_train[\"label\"]=i\n",
    "    df_all.append(df_train)\n",
    "\n",
    "df_train=pd.concat(df_all).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = [i for i in df_test.columns]\n",
    "label = df_train[\"label\"]\n",
    "df_test_,feats_=extract_segmented_features(df_test[feats].to_numpy(),256,0)\n",
    "df_train_,feats_=extract_segmented_features(df_train[feats].to_numpy(),256,0)\n",
    "\n",
    "df_train_[\"label\"]=label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------- 0\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[200]\tvalid_0's multi_error: 0.04875\n",
      "--------------------------- 1\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[303]\tvalid_0's multi_error: 0.035\n",
      "--------------------------- 2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[122]\tvalid_0's multi_error: 0.04\n",
      "--------------------------- 3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[169]\tvalid_0's multi_error: 0.05\n",
      "--------------------------- 4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[352]\tvalid_0's multi_error: 0.04\n"
     ]
    }
   ],
   "source": [
    "pred_y, oof, feats_importance=model_train_multiclassifier(df_train_,df_test_,feats_,2002,\"label\",5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0_256_median_4</td>\n",
       "      <td>2381.989865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0_256_max_freq_16</td>\n",
       "      <td>2258.676743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0_256_kurtosis_8</td>\n",
       "      <td>1800.905646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0_256_median_10</td>\n",
       "      <td>1538.679517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0_256_skewness_12</td>\n",
       "      <td>1477.106827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0_256_std_12</td>\n",
       "      <td>10.135400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0_256_kurtosis_12</td>\n",
       "      <td>9.748671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0_256_mean_4</td>\n",
       "      <td>9.014367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0_256_std_6</td>\n",
       "      <td>8.487221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0_256_median_14</td>\n",
       "      <td>4.630590</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 name   importance\n",
       "35     0_256_median_4  2381.989865\n",
       "95  0_256_max_freq_16  2258.676743\n",
       "71   0_256_kurtosis_8  1800.905646\n",
       "41    0_256_median_10  1538.679517\n",
       "59  0_256_skewness_12  1477.106827\n",
       "..                ...          ...\n",
       "27       0_256_std_12    10.135400\n",
       "75  0_256_kurtosis_12     9.748671\n",
       "3        0_256_mean_4     9.014367\n",
       "21        0_256_std_6     8.487221\n",
       "45    0_256_median_14     4.630590\n",
       "\n",
       "[96 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.95725\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(label,np.argmax(oof,axis=1)))\n",
    "df_test[\"label\"]=np.argmax(pred_y,axis=1)\n",
    "df_test[[\"label\"]].to_csv(\"lgb_{:.4f}.csv\".format(accuracy_score(label,np.argmax(oof,axis=1))),header=None,index=False) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
